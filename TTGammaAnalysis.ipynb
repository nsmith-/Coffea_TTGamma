{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from coffea import hist, util\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "import coffea.processor as processor\n",
    "from functools import partial\n",
    "import uproot\n",
    "\n",
    "from awkward import JaggedArray\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from coffea.lookup_tools import extractor, dense_lookup\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker,colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.crossSections import crossSections, lumis\n",
    "from utils.efficiencies import getMuSF, getEleSF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('utils/taggingEfficienciesDenseLookup.pkl','rb') as _file:\n",
    "    taggingEffLookup = pickle.load(_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at ProcessorABC to see the expected methods and what they are supposed to do\n",
    "class TTGammaProcessor(processor.ProcessorABC):\n",
    "#     def __init__(self, runNum = -1, eventNum = -1):\n",
    "    def __init__(self, runNum = -1, eventNum = -1, mcSumWeights = None):\n",
    "        dataset_axis = hist.Cat(\"dataset\", \"Dataset\")\n",
    "        year_axis = hist.Cat(\"year\",r\"Year\")\n",
    "        \n",
    "        Npho_axis = hist.Bin(\"nPho\", r\"$Number of Photons$\", 3, 0., 3)\n",
    "        Nbjet_axis = hist.Bin(\"nBjet\", r\"BJet Multiplicity\", 3, 0, 3)\n",
    "        lep_axis = hist.Bin(\"lepFlavor\", r\"ElectronOrMuon\", 3, -1.5, 1.5)\n",
    "        \n",
    "        m3_axis = hist.Bin(\"M3\", r\"$M_3$ [GeV]\", 1000, 0., 1000)\n",
    "        pt_axis = hist.Bin(\"pt\", r\"$p_{T}$ [GeV]\", 200, 0., 1000)\n",
    "        genpt_axis = hist.Bin(\"genpt\", r\"$Gen p_{T,\\gamma}$ [GeV]\", 200, 0., 1000)\n",
    "        eta_axis = hist.Bin(\"eta\", r\"$\\eta_{\\gamma}$\", 300, -1.5, 1.5)\n",
    "        geneta_axis = hist.Bin(\"geneta\", r\"$Gen \\eta_{\\gamma}$\", 300, -1.5, 1.5)\n",
    "        sieie_axis = hist.Bin(\"sieie\", r\"$\\sigma_{i\\eta i\\eta}$\", 100, 0., 0.1)\n",
    "        chIso_axis = hist.Bin(\"chIso\", r\"Charged Hadron Isolation\", 200, 0., 20.)\n",
    "        dR_axis = hist.Bin(\"dR\", r\"$\\Delta R$\", 600, 0., 6)\n",
    "        mult_axis = hist.Bin(\"N\", r\"Multiplicity\", 10, 0, 10)\n",
    "\n",
    "        ## Define axis to keep track of photon category\n",
    "        phoCategory_axis = hist.Bin(\"category\", r\"Photon Category\", [1,2,3,4,5])\n",
    "        phoCategory_axis.identifiers()[0].label = \"Genuine Photon\"    \n",
    "        phoCategory_axis.identifiers()[1].label = \"Misidentified Electron\"    \n",
    "        phoCategory_axis.identifiers()[2].label = \"Hadronic Photon\"    \n",
    "        phoCategory_axis.identifiers()[3].label = \"Hadronic Fake\"    \n",
    "        \n",
    "        ###\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            ##photon histograms\n",
    "            'photon_pt': hist.Hist(\"Counts\", dataset_axis, pt_axis, phoCategory_axis, year_axis,lep_axis),\n",
    "            'photon_eta': hist.Hist(\"Counts\", dataset_axis, eta_axis, phoCategory_axis, year_axis,lep_axis),\n",
    "            'photon_sieie': hist.Hist(\"Counts\", dataset_axis, sieie_axis, phoCategory_axis, year_axis,lep_axis),\n",
    "            'photon_chIso': hist.Hist(\"Counts\", dataset_axis, chIso_axis, phoCategory_axis, year_axis,lep_axis),\n",
    "            'dR_lep_gamma': hist.Hist(\"Counts\", dataset_axis, dR_axis,phoCategory_axis, year_axis,lep_axis),\n",
    "\n",
    "            ##photon reco vs gen histograms\n",
    "            'photon_RecoVsGenPt': hist.Hist(\"Counts\", dataset_axis, pt_axis,genpt_axis, phoCategory_axis, year_axis,lep_axis),\n",
    "            'photon_RecoVsGenEta': hist.Hist(\"Counts\", dataset_axis, eta_axis,geneta_axis, phoCategory_axis, year_axis,lep_axis),\n",
    "\n",
    "            ##jet histograms (split by nBjet, nPhoton, and lepton flavor)\n",
    "            'pt_jet': hist.Hist(\"Counts\", dataset_axis, pt_axis, year_axis,Npho_axis,Nbjet_axis,lep_axis),\n",
    "            'jet_mult': hist.Hist(\"Counts\", dataset_axis, mult_axis, year_axis,Npho_axis,Nbjet_axis,lep_axis),\n",
    "            'M3': hist.Hist(\"Counts\", dataset_axis, m3_axis, year_axis,Npho_axis,Nbjet_axis,lep_axis),\n",
    "\n",
    "        })\n",
    "\n",
    "        self.eventNum = eventNum\n",
    "        self.runNum = runNum\n",
    "        self.mcSumWeights = mcSumWeights\n",
    "        \n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    def process(self, df):\n",
    "        output = self.accumulator.identity()\n",
    "\n",
    "        datasetFull = df['dataset']\n",
    "        if '2016' in datasetFull:\n",
    "            year=2016\n",
    "            yearStr=\"2016\"\n",
    "            muonTrigger = df['HLT_IsoMu24'] | df['HLT_IsoTkMu24']\n",
    "            eleTrigger = df['HLT_Ele27_WPTight_Gsf']\n",
    "            photonBitMapName = 'Photon_cutBased'\n",
    "            btagSF = 'test_DeepCSV_2016LegacySF_V1.btag.csv'\n",
    "            dataset=datasetFull.replace('_2016','')\n",
    "        elif '2017' in datasetFull:\n",
    "            year=2017\n",
    "            yearStr=\"2017\"\n",
    "            muonTrigger = df['HLT_IsoMu27']\n",
    "            eleTrigger = df['HLT_Ele32_WPTight_Gsf_L1DoubleEG'] | df['HLT_Ele32_WPTight_Gsf']\n",
    "            photonBitMapName = 'Photon_cutBasedBitmap'\n",
    "            btagSF = 'test_DeepCSV_102XSF_V1.btag.csv'\n",
    "            dataset=datasetFull.replace('_2017','')\n",
    "        elif '2018' in datasetFull:\n",
    "            year=2018\n",
    "            yearStr=\"2018\"\n",
    "            muonTrigger = df['HLT_IsoMu24']\n",
    "            eleTrigger = df['HLT_Ele32_WPTight_Gsf']\n",
    "            photonBitMapName = 'Photon_cutBasedBitmap'\n",
    "            btagSF = 'test_DeepCSV_102XSF_V1.btag.csv'\n",
    "            dataset=datasetFull.replace('_2018','')\n",
    "\n",
    "        if dataset in ['SingleElectron', 'SingleMuon', 'EGamma']:\n",
    "            isRealData = True\n",
    "        else:\n",
    "            isRealData = False\n",
    "            mcSumWeight = self.mcSumWeights[datasetFull]\n",
    "            xsec = crossSections[dataset]\n",
    "        \n",
    "        \n",
    "        filters = (df['Flag_goodVertices'] &\n",
    "                   df['Flag_globalSuperTightHalo2016Filter'] &\n",
    "                   df['Flag_HBHENoiseFilter'] &\n",
    "                   df['Flag_HBHENoiseIsoFilter'] &\n",
    "                   df['Flag_EcalDeadCellTriggerPrimitiveFilter'] &\n",
    "                   df['Flag_BadPFMuonFilter'] \n",
    "                  )\n",
    "        if year > 2016:\n",
    "            filters = (filters & \n",
    "                       df['Flag_ecalBadCalibFilterV2']\n",
    "                      )\n",
    "        \n",
    "        \n",
    "        \n",
    "        muons = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nMuon'],\n",
    "            pt=df['Muon_pt'],\n",
    "            eta=df['Muon_eta'],\n",
    "            phi=df['Muon_phi'],\n",
    "            mass=df['Muon_mass'],\n",
    "            charge=df['Muon_charge'],\n",
    "            relIso=df['Muon_pfRelIso04_all'],\n",
    "            tightId=df['Muon_tightId'],\n",
    "            isPFcand=df['Muon_isPFcand'],\n",
    "            isTracker=df['Muon_isTracker'],\n",
    "            isGlobal=df['Muon_isGlobal'],           \n",
    "        )\n",
    "        \n",
    "        electrons = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nElectron'],\n",
    "            pt=df['Electron_pt'],\n",
    "            eta=df['Electron_eta'],\n",
    "            phi=df['Electron_phi'],\n",
    "            mass=df['Electron_mass'],\n",
    "            charge=df['Electron_charge'],\n",
    "            cutBased=df['Electron_cutBased'],\n",
    "            d0=df['Electron_dxy'],\n",
    "            dz=df['Electron_dz'],\n",
    "        )\n",
    "\n",
    "        jets = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nJet'],\n",
    "            pt=df['Jet_pt'],\n",
    "            eta=df['Jet_eta'],\n",
    "            phi=df['Jet_phi'],\n",
    "            mass=df['Jet_mass'],\n",
    "            jetId=df['Jet_jetId'],\n",
    "            btag=df['Jet_btagDeepB'],\n",
    "            hadFlav=df['Jet_hadronFlavour'],\n",
    "            genIdx=df['Jet_genJetIdx'],\n",
    "        )\n",
    "\n",
    "        photons = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nPhoton'],\n",
    "            pt=df['Photon_pt'],\n",
    "            eta=df['Photon_eta'],\n",
    "            phi=df['Photon_phi'],\n",
    "            mass=np.zeros_like(df['Photon_pt']),\n",
    "            isEE=df['Photon_isScEtaEE'],\n",
    "            isEB=df['Photon_isScEtaEB'],\n",
    "            photonId=df[photonBitMapName],\n",
    "            passEleVeto=df['Photon_electronVeto'],\n",
    "            pixelSeed=df['Photon_pixelSeed'],\n",
    "            #genFlav=df['Photon_genPartFlav'],\n",
    "            genIdx=df['Photon_genPartIdx'],\n",
    "            sieie=df['Photon_sieie'],\n",
    "            chIso=df['Photon_pfRelIso03_chg'],\n",
    "            vidCuts=df['Photon_vidNestedWPBitmap'],\n",
    "        )\n",
    "            \n",
    "        genPart = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nGenPart'],\n",
    "            pt=df['GenPart_pt'],\n",
    "            eta=df['GenPart_eta'],\n",
    "            phi=df['GenPart_phi'],\n",
    "            mass=df['GenPart_mass'],\n",
    "            pdgid=df['GenPart_pdgId'],\n",
    "            motherIdx=df['GenPart_genPartIdxMother'],\n",
    "            status=df['GenPart_status'],\n",
    "            statusFlags=df['GenPart_statusFlags'],\n",
    "        )\n",
    "\n",
    "\n",
    "        ## TTbar vs TTGamma Overlap Removal (work in progress, still buggy)\n",
    "#         overlapRemoval = np.ones_like(df['event'])\n",
    "#         if 'TTbar' in dataset:\n",
    "#             overlapPhoSelect = ((genPart.pt>=10) & \n",
    "#                                 (abs(genPart.eta) < 5.) & \n",
    "#                                 (genPart.pdgid==22) & \n",
    "#                                 (genPart.status==1)\n",
    "#                                )\n",
    "            \n",
    "#             OverlapPhotons = genPart[overlapPhoSelect] \n",
    "\n",
    "#             phoParent = OverlapPhotons.motherIdx\n",
    "#             phoParent = phoParent[phoParent>-1]\n",
    "#             isNonPrompt = (genPart[phoParent].pdgid>25).any()\n",
    "\n",
    "#             while (phoParent>-1).any().sum()>0:\n",
    "#                 phoParent = phoParent[phoParent>-1]\n",
    "#                 isNonPrompt = isNonPrompt | (genPart[phoParent].pdgid>37).any()\n",
    "#                 phoParent = genPart[phoParent].motherIdx        \n",
    "#             ### Add in min DR cut\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        muonSelectTight = ((muons.pt>30) & \n",
    "                           (abs(muons.eta)<2.4) & \n",
    "                           (muons.tightId) & \n",
    "                           (muons.relIso < 0.15)\n",
    "                          )\n",
    "        \n",
    "        muonSelectLoose = ((muons.pt>15) & \n",
    "                           (abs(muons.eta)<2.4) & \n",
    "                           ((muons.isPFcand) & (muons.isTracker | muons.isGlobal)) & \n",
    "                           (muons.relIso < 0.25) &\n",
    "                           np.invert(muonSelectTight)\n",
    "                          )\n",
    "\n",
    "        eleEtaGap = (abs(electrons.eta) < 1.4442) | (abs(electrons.eta) > 1.566)\n",
    "        elePassD0 = ((abs(electrons.eta) < 1.479) & (abs(electrons.d0) < 0.05) |\n",
    "                     (abs(electrons.eta) > 1.479)  & (abs(electrons.d0) < 0.1)\n",
    "                    )\n",
    "        elePassDZ = ((abs(electrons.eta) < 1.479) & (abs(electrons.dz) < 0.1) |\n",
    "                     (abs(electrons.eta) > 1.479)  & (abs(electrons.dz) < 0.2)\n",
    "                    )\n",
    "\n",
    "        \n",
    "        \n",
    "        electronSelectTight = ((electrons.pt>35) & \n",
    "                               (abs(electrons.eta)<2.1) & \n",
    "                               eleEtaGap &      \n",
    "                               (electrons.cutBased>=4) &\n",
    "                               elePassD0 & \n",
    "                               elePassDZ\n",
    "                              )\n",
    "\n",
    "        electronSelectLoose = ((electrons.pt>15) & \n",
    "                               (abs(electrons.eta)<2.4) & \n",
    "                               eleEtaGap &      \n",
    "                               (electrons.cutBased>=1) &\n",
    "                               elePassD0 & \n",
    "                               elePassDZ & \n",
    "                               np.invert(electronSelectTight)\n",
    "                              )\n",
    "        \n",
    "        tightMuon = muons[muonSelectTight]\n",
    "        looseMuon = muons[muonSelectLoose]\n",
    "        \n",
    "        tightElectron = electrons[electronSelectTight]\n",
    "        looseElectron = electrons[electronSelectLoose]\n",
    "\n",
    "        \n",
    "\n",
    "                \n",
    "        oneMuon = (tightMuon.counts == 1)\n",
    "        muVeto = (tightMuon.counts == 0)\n",
    "        oneEle = (tightElectron.counts == 1)\n",
    "        eleVeto = (tightElectron.counts == 0)\n",
    "        looseMuonSel = (looseMuon.counts == 0)\n",
    "        looseElectronSel = (looseElectron.counts == 0)\n",
    "\n",
    "        \n",
    "        #### Calculate deltaR between photon and nearest muon\n",
    "        ####### make combination pairs\n",
    "        phoMu = photons['p4'].cross(tightMuon['p4'],nested=True)\n",
    "        ####### check delta R of each combination, if min is >0.1 it is okay, or if there are no tight muons it passes\n",
    "        dRphomu = (phoMu.i0.delta_r(phoMu.i1)>0.4).all() | (tightMuon.counts==0)\n",
    "        phoEle = photons['p4'].cross(tightElectron['p4'],nested=True)\n",
    "        dRphoele = ((phoEle.i0.delta_r(phoEle.i1)).min()>0.4) | (tightElectron.counts==0)\n",
    "        \n",
    "        #photon selection (no ID requirement used here)\n",
    "        photonSelect = ((photons.pt>20) & \n",
    "                        (abs(photons.eta) < 1.4442) &\n",
    "                        (photons.isEE | photons.isEB) &\n",
    "                        (photons.passEleVeto) & \n",
    "                        np.invert(photons.pixelSeed) & \n",
    "                        dRphomu & dRphoele\n",
    "                       )\n",
    "        \n",
    "        \n",
    "        #split out the ID requirement, enabling Iso and SIEIE to be inverted for control regions\n",
    "        photonID = photons.photonId >= 2\n",
    "\n",
    "        #parse VID cuts, define loose photons (not used yet)\n",
    "        photon_MinPtCut = (photons.vidCuts>>0 & 3)>=2 \n",
    "        photon_PhoSCEtaMultiRangeCut = (photons.vidCuts>>2 & 3)>=2 \n",
    "        photon_PhoSingleTowerHadOverEmCut = (photons.vidCuts>>4 & 3)>=2  \n",
    "        photon_PhoFull5x5SigmaIEtaIEtaCut = (photons.vidCuts>>6 & 3)>=2  \n",
    "        photon_PhoAnyPFIsoWithEACut = (photons.vidCuts>>8 & 3)>=2  \n",
    "        photon_PhoAnyPFIsoWithEAAndQuadScalingCut = (photons.vidCuts>>10 & 3)>=2  \n",
    "        photon_PhoAnyPFIsoWithEACut = (photons.vidCuts>>12 & 3)>=2  \n",
    "        \n",
    "        loosePhotonID = photon_PhoSingleTowerHadOverEmCut & photon_PhoAnyPFIsoWithEACut & photon_PhoAnyPFIsoWithEAAndQuadScalingCut & photon_PhoAnyPFIsoWithEACut\n",
    "\n",
    "        \n",
    "        tightPhotons = photons[photonSelect & photonID]\n",
    "\n",
    "        \n",
    "        ##medium jet ID cut\n",
    "        jetIDbit = 1\n",
    "        if year>2016: jetIDbit=2\n",
    "\n",
    "        ##check dR jet,lepton & jet,photon\n",
    "        jetMu = jets['p4'].cross(tightMuon['p4'],nested=True)\n",
    "        dRjetmu = ((jetMu.i0.delta_r(jetMu.i1)).min()>0.4) | (tightMuon.counts==0)\n",
    "\n",
    "        jetEle = jets['p4'].cross(tightElectron['p4'],nested=True)\n",
    "        dRjetele = ((jetEle.i0.delta_r(jetEle.i1)).min()>0.4) | (tightElectron.counts==0)\n",
    "\n",
    "        jetPho = jets['p4'].cross(tightPhotons['p4'],nested=True)\n",
    "        dRjetpho = ((jetPho.i0.delta_r(jetPho.i1)).min()>0.1) | (tightPhotons.counts==0)\n",
    "        \n",
    "        jetSelect = ((jets.pt > 30) &\n",
    "                     (abs(jets.eta) < 2.4) &\n",
    "                     ((jets.jetId >> jetIDbit & 1)==1) &\n",
    "                     dRjetmu & dRjetele & dRjetpho                    \n",
    "                    )\n",
    "\n",
    "        tightJets = jets[jetSelect]\n",
    "        \n",
    "        bTagWP = 0.6321\n",
    "        if year == 2017:\n",
    "            bTagWP = 0.4941\n",
    "        if year == 2018:\n",
    "            bTagWP = 0.4184\n",
    "\n",
    "        btagged = tightJets.btag>bTagWP\n",
    "\n",
    "        bJets = tightJets[btagged]\n",
    "\n",
    "        ## Define M3, mass of 3-jet pair with highest pT\n",
    "        triJet = tightJets['p4'].choose(3)\n",
    "\n",
    "        triJetPt = (triJet.i0 + triJet.i1 + triJet.i2).pt\n",
    "        triJetMass = (triJet.i0 + triJet.i1 + triJet.i2).mass\n",
    "        M3 = triJetMass[triJetPt.argmax()]\n",
    "\n",
    "\n",
    "        leadingPhoton = tightPhotons[:,:1]\n",
    "\n",
    "        #calculate dR lepton,photon\n",
    "        gammaMu = leadingPhoton['p4'].cross(tightMuon['p4'],nested=True)\n",
    "        dRgammaMu = (gammaMu.i0.delta_r(gammaMu.i1)).min()\n",
    "        gammaEle = leadingPhoton['p4'].cross(tightElectron['p4'],nested=True)\n",
    "        dRgammaEle = (gammaEle.i0.delta_r(gammaEle.i1)).min()\n",
    "\n",
    "        dRgammaLep = np.minimum(dRgammaMu,dRgammaEle)        \n",
    "\n",
    "        \n",
    "        #### Photon categories, using genIdx branch\n",
    "        # reco photons really generated as electrons\n",
    "        isMisIDele = (abs(genPart[leadingPhoton.genIdx].pdgid)==13).any()\n",
    "\n",
    "        matchedPho = (abs(genPart[leadingPhoton.genIdx].pdgid)==22).any()\n",
    "\n",
    "        # look through parentage to find if any hadrons in genPhoton parent history\n",
    "        genParent = genPart[leadingPhoton.genIdx].motherIdx\n",
    "        isHadPho = (genPart[leadingPhoton.genIdx].pdgid>25).any()\n",
    "        while (genParent>-1).any().sum()>0:\n",
    "            genParent = genParent[genParent>-1]\n",
    "            isHadPho = isHadPho | (genPart[genParent].pdgid>25).any()\n",
    "            genParent = genPart[genParent].motherIdx\n",
    "\n",
    "        \n",
    "        isHadFake = (leadingPhoton.genIdx==-1).any()\n",
    "        isHadFake = isHadFake & np.invert(isHadPho)\n",
    "\n",
    "        isGenPho = matchedPho & np.invert(isHadPho)\n",
    "\n",
    "        #define integer definition for the photon category axis\n",
    "        phoCategory = 1*isGenPho + 2*isMisIDele + 3*isHadPho + 4*isHadFake\n",
    "\n",
    "        \n",
    "        #define selection levels (for cutflow synchronization)\n",
    "        mu_trigger = muonTrigger        \n",
    "        mu_filter = mu_trigger & filters\n",
    "        mu_oneMu = oneMuon & mu_filter\n",
    "        mu_noEle = eleVeto & mu_oneMu\n",
    "        mu_noLoose = looseMuonSel & looseElectronSel & mu_noEle\n",
    "        mu_twoJet = (tightJets.counts >= 2) & mu_noLoose\n",
    "        mu_threeJet = (tightJets.counts >= 3) & mu_noLoose\n",
    "        mu_jetSel = (tightJets.counts >= 4) & mu_noLoose\n",
    "        mu_bjetSel = (bJets.counts >= 2) & mu_jetSel\n",
    "        mu_presel = mu_bjetSel\n",
    "        mu_phosel = (tightPhotons.counts >= 1) & mu_bjetSel\n",
    "\n",
    "        ele_trigger = eleTrigger\n",
    "        ele_filter = ele_trigger & filters\n",
    "        ele_oneEle = oneEle & ele_filter\n",
    "        ele_noMu = muVeto & ele_oneEle\n",
    "        ele_noLoose = looseMuonSel & looseElectronSel & ele_noMu\n",
    "        ele_twoJet = (tightJets.counts >= 2) & ele_noLoose\n",
    "        ele_threeJet = (tightJets.counts >= 3) & ele_noLoose\n",
    "        ele_jetSel = (tightJets.counts >= 4) & ele_noLoose\n",
    "        ele_bjetSel = (bJets.counts >= 2) & ele_jetSel\n",
    "        ele_presel = ele_bjetSel\n",
    "        ele_phosel = (tightPhotons.counts >= 1) & ele_bjetSel\n",
    "\n",
    "        \n",
    "        \n",
    "        lep_jetSel = mu_jetSel | ele_jetSel\n",
    "        lep_bjetSel = mu_bjetSel | ele_bjetSel\n",
    "        lep_phosel = mu_phosel | ele_phosel\n",
    "        \n",
    "        lepFlavor = -1*ele_noLoose + 1*mu_noLoose\n",
    "        \n",
    "\n",
    "        #get leading generated photon, for \n",
    "        genPhotonSel =  ((genPart.pdgid==22) &\n",
    "                         (genPart.statusFlags&1==1) &\n",
    "                         (genPart.statusFlags>>13&1==1))\n",
    "        genPhotons = genPart[genPhotonSel]\n",
    "        \n",
    "        #find highest Pt, otherwise they are sorted by gen history\n",
    "        leadingGenPhoton = genPhotons[genPhotons.pt==genPhotons.pt.max()]\n",
    "    \n",
    "        ext = extractor()\n",
    "        ext.add_weight_sets([\"btag * ScaleFactors/Btag/%s\"%btagSF])\n",
    "        ext.finalize()\n",
    "        evaluator = ext.make_evaluator()\n",
    "        \n",
    "        #btag key name\n",
    "        #name / working Point / type / systematic / jetType\n",
    "        #  ... / 0-loose 1-medium 2-tight / comb,mujets,iterativefit / central,up,down / 0-b 1-c 2-udcsg \n",
    "        bJetSF = evaluator['btagDeepCSV_1_comb_central_0'](tightJets.eta, tightJets.pt, tightJets.btag)\n",
    "        bJetSF_c = evaluator['btagDeepCSV_1_comb_central_1'](tightJets.eta, tightJets.pt, tightJets.btag)\n",
    "        bJetSF_udcsg = evaluator['btagDeepCSV_1_incl_central_2'](tightJets.eta, tightJets.pt, tightJets.btag)\n",
    "\n",
    "        bJetSF.content[(tightJets.hadFlav==4).content] = bJetSF_c[tightJets.hadFlav==4].content\n",
    "        bJetSF.content[(tightJets.hadFlav==0).content] = bJetSF_udcsg[tightJets.hadFlav==0].content\n",
    "        \n",
    "\n",
    "        ## mc efficiency lookup, data efficiency is eff* scale factor\n",
    "        btagEfficiencies = taggingEffLookup(datasetFull,tightJets.hadFlav,tightJets.pt,tightJets.eta)\n",
    "        btagEfficienciesData = btagEfficiencies*bJetSF\n",
    "\n",
    "        ##probability is the product of all efficiencies of tagged jets, times product of 1-eff for all untagged jets\n",
    "        ## https://twiki.cern.ch/twiki/bin/view/CMS/BTagSFMethods#1a_Event_reweighting_using_scale\n",
    "        pMC   = btagEfficiencies[btagged].prod()     * (1.-btagEfficiencies[np.invert(btagged)]).prod() \n",
    "        pData = btagEfficienciesData[btagged].prod() * (1.-btagEfficienciesData[np.invert(btagged)]).prod()\n",
    "        btagWeight = pData/pMC\n",
    "        \n",
    "\n",
    "        eleSF, eleSFup, eleSFdo = getEleSF(tightElectron.pt, tightElectron.eta, year)\n",
    "        muSF, muSFup, muSFdo = getMuSF(tightMuon.pt, tightMuon.eta, year)\n",
    "        \n",
    "        \n",
    "        evtWeight = np.ones(df.size)\n",
    "        if not isRealData:\n",
    "            evtWeight *= df['genWeight']\n",
    "            evtWeight *= xsec * lumis[year] / mcSumWeight\n",
    "            # FIXME: some issue with btag weight evaluation giving NaN for jets in pt 200-400\n",
    "            #evtWeight *= btagWeight\n",
    "            evtWeight *= eleSF\n",
    "            evtWeight *= muSF\n",
    "        \n",
    "        output['photon_pt'].fill(dataset=dataset,\n",
    "                                 pt=tightPhotons.p4.pt[:,:1][lep_phosel].flatten(),\n",
    "                                 category=phoCategory[lep_phosel].flatten(),\n",
    "                                 year=yearStr,\n",
    "                                 lepFlavor=lepFlavor[lep_phosel],\n",
    "                                 weight=evtWeight[lep_phosel].flatten())\n",
    "        output['photon_eta'].fill(dataset=dataset,\n",
    "                                  eta=tightPhotons.eta[:,:1][lep_phosel].flatten(),\n",
    "                                  category=phoCategory[lep_phosel].flatten(),\n",
    "                                  year=yearStr,\n",
    "                                  lepFlavor=lepFlavor[lep_phosel],\n",
    "                                  weight=evtWeight[lep_phosel].flatten())\n",
    "        if 'TTGamma' in dataset:\n",
    "            output['photon_RecoVsGenPt'].fill(dataset=dataset,\n",
    "                                              pt=tightPhotons.pt[:,:1][lep_phosel].flatten(),\n",
    "                                              genpt=leadingGenPhoton.pt[:,:1][lep_phosel].flatten(),\n",
    "                                              category=phoCategory[lep_phosel].flatten(),\n",
    "                                              year=yearStr,\n",
    "                                              lepFlavor=lepFlavor[lep_phosel],\n",
    "                                              weight=evtWeight[lep_phosel].flatten())\n",
    "            output['photon_RecoVsGenEta'].fill(dataset=dataset,\n",
    "                                               eta=tightPhotons.eta[:,:1][lep_phosel].flatten(),\n",
    "                                               geneta=leadingGenPhoton.eta[:,:1][lep_phosel].flatten(),\n",
    "                                               category=phoCategory[lep_phosel].flatten(),\n",
    "                                               year=yearStr,\n",
    "                                               lepFlavor=lepFlavor[lep_phosel],\n",
    "                                               weight=evtWeight[lep_phosel].flatten())\n",
    "        output['photon_sieie'].fill(dataset=dataset,\n",
    "                                    sieie=tightPhotons.sieie[:,:1][lep_phosel].flatten(),\n",
    "                                    category=phoCategory[lep_phosel].flatten(),\n",
    "                                    year=yearStr,\n",
    "                                    lepFlavor=lepFlavor[lep_phosel],\n",
    "                                    weight=evtWeight[lep_phosel].flatten())\n",
    "\n",
    "        output['photon_chIso'].fill(dataset=dataset,\n",
    "                                    chIso=tightPhotons.chIso[:,:1][lep_phosel].flatten(),\n",
    "                                    category=phoCategory[lep_phosel].flatten(),\n",
    "                                    year=yearStr,\n",
    "                                    lepFlavor=lepFlavor[lep_phosel],\n",
    "                                    weight=evtWeight[lep_phosel].flatten())\n",
    "\n",
    "        output['dR_lep_gamma'].fill(dataset=dataset,\n",
    "                                    dR=dRgammaLep[lep_phosel].flatten(),\n",
    "                                    category=phoCategory[lep_phosel].flatten(),\n",
    "                                    year=yearStr,\n",
    "                                    lepFlavor=lepFlavor[lep_phosel],\n",
    "                                    weight=evtWeight[lep_phosel].flatten())\n",
    "\n",
    "        output['pt_jet'].fill(dataset=dataset,\n",
    "                              pt=tightJets.p4.pt[:,:1][lep_jetSel].flatten(),\n",
    "                              year=yearStr,\n",
    "                              nPho=tightPhotons[lep_jetSel].counts.flatten(),\n",
    "                              nBjet=bJets[lep_jetSel].counts.flatten(),\n",
    "                              lepFlavor=lepFlavor[lep_jetSel],\n",
    "                              weight=evtWeight[lep_jetSel].flatten())\n",
    "        output['jet_mult'].fill(dataset=dataset,\n",
    "                                N=tightJets[lep_jetSel].counts.flatten(),\n",
    "                                year=yearStr,\n",
    "                                nPho=tightPhotons[lep_jetSel].counts.flatten(),\n",
    "                                nBjet=bJets[lep_jetSel].counts.flatten(),\n",
    "                                lepFlavor=lepFlavor[lep_jetSel],\n",
    "                                weight=evtWeight[lep_jetSel].flatten())\n",
    "        output['M3'].fill(dataset=dataset,\n",
    "                          M3=M3[lep_jetSel].flatten(),\n",
    "                          year=yearStr,\n",
    "                          nPho=tightPhotons[lep_jetSel].counts.flatten(),\n",
    "                          nBjet=bJets[lep_jetSel].counts.flatten(),\n",
    "                          lepFlavor=lepFlavor[lep_jetSel],\n",
    "#                           category=phoCategory[mu_phosel].flatten(),\n",
    "                          weight=evtWeight[lep_jetSel].flatten())\n",
    "\n",
    "\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCWeightSum(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        self._genw = processor.defaultdict_accumulator(float)\n",
    "    \n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._genw\n",
    "    \n",
    "    def process(self, df):\n",
    "        out = self.accumulator.identity()\n",
    "        out[df['dataset']] += df['genEventSumw'].sum()\n",
    "        return out\n",
    "        \n",
    "    def postprocess(self, acc):\n",
    "        return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1d06c1059a4537bd5e7b77740a9bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Preprocessing', max=11, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc9d693f6ae438e95f01e1f1742ca76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Processing', max=12, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "defaultdict_accumulator(<class 'float'>, {'WGamma_2016': 431218385.23342997, 'TTbar_2016': 408626493.5750917, 'ZGamma_2016': 109249699.21376002, 'TTGamma_Dilept_2016': 58081.83072544624, 'TTGamma_SingleLept_2016': 1479820.2680320474})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a85203dd975484697bfe415b088d6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Preprocessing', max=11, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6f724dd19e4944b4c5106df27a0bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Processing', max=32, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/ipython/7.2.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:436: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/Cellar/ipython/7.2.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:436: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/Cellar/ipython/7.2.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:436: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/Cellar/ipython/7.2.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:436: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/Cellar/ipython/7.2.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:436: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/Cellar/ipython/7.2.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:436: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/Cellar/ipython/7.2.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:436: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/Cellar/ipython/7.2.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:436: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/Cellar/ipython/7.2.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:436: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/Cellar/ipython/7.2.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:436: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "147.01381301879883\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "\n",
    "fileset = {\n",
    "    'TTGamma_Dilept_2016': [\n",
    "        'data/TTGamma_Dilept_TuneCP5_PSweights_13TeV-madgraph-pythia8.0.root',\n",
    "        'data/TTGamma_Dilept_TuneCP5_PSweights_13TeV-madgraph-pythia8.1.root',\n",
    "    ],\n",
    "    'TTGamma_SingleLept_2016': [\n",
    "        'data/TTGamma_SingleLept_TuneCP5_PSweights_13TeV-madgraph-pythia8.0.root',\n",
    "        'data/TTGamma_SingleLept_TuneCP5_PSweights_13TeV-madgraph-pythia8.1.root',\n",
    "    ],\n",
    "    # 'TTGamma_Hadronic': [],\n",
    "    'TTbar_2016': [\n",
    "        'data/TTTo2L2Nu_TuneCP5_PSweights_13TeV-powheg-pythia8.0.root',\n",
    "        'data/TTTo2L2Nu_TuneCP5_PSweights_13TeV-powheg-pythia8.0.root',\n",
    "        'data/TTToSemiLeptonic_TuneCP5_PSweights_13TeV-powheg-pythia8.0.root',\n",
    "        'data/TTToSemiLeptonic_TuneCP5_PSweights_13TeV-powheg-pythia8.1.root'\n",
    "    ],\n",
    "    'ZGamma_2016': [\n",
    "        'data/ZGToLLG_01J_5f_TuneCUETP8M1_13TeV-amcatnloFXFX-pythia8.0.root',\n",
    "        'data/ZGToLLG_01J_5f_TuneCUETP8M1_13TeV-amcatnloFXFX-pythia8.1.root',\n",
    "    ],\n",
    "    'WGamma_2016': [\n",
    "        'data/WGToLNuG_01J_5f_TuneCUETP8M1_13TeV-amcatnloFXFX-pythia8.0.root',\n",
    "        'data/WGToLNuG_01J_5f_TuneCUETP8M1_13TeV-amcatnloFXFX-pythia8.1.root',\n",
    "    ]\n",
    "}\n",
    "\n",
    "filemeta = {}\n",
    "\n",
    "mcSumWeights = processor.run_uproot_job(fileset,\n",
    "                                  treename='Runs',\n",
    "                                  processor_instance=MCWeightSum(),\n",
    "                                  executor=processor.futures_executor,\n",
    "                                  executor_args={'workers': 4, 'flatten': True},\n",
    "                                  metadata_cache=filemeta,\n",
    "                                 )\n",
    "print(mcSumWeights)\n",
    "\n",
    "output = processor.run_uproot_job(fileset,\n",
    "                                  treename='Events',\n",
    "                                  processor_instance=TTGammaProcessor(mcSumWeights=mcSumWeights),\n",
    "                                  executor=processor.futures_executor,\n",
    "                                  executor_args={'workers': 4, 'flatten': True},\n",
    "                                  metadata_cache=filemeta,\n",
    "                                 )\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.save(output, 'ttgamma.coffea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de291dbdabd411a8338395065314dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Processing', max=5, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/ipython/7.2.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:436: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/Cellar/ipython/7.2.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:436: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pyinstrument import Profiler\n",
    "\n",
    "profiler = Profiler()\n",
    "\n",
    "profiler.start()\n",
    "_, metrics = processor.run_uproot_job(fileset,\n",
    "                                  treename='Events',\n",
    "                                  processor_instance=TTGammaProcessor(mcSumWeights=mcSumWeights),\n",
    "                                  executor=processor.iterative_executor,\n",
    "                                  executor_args={'flatten': True, 'savemetrics': True},\n",
    "                                  metadata_cache=filemeta,\n",
    "                                  maxchunks=1,\n",
    "                                 )\n",
    "profiler.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columns': {'Electron_charge',\n",
       "  'Electron_cutBased',\n",
       "  'Electron_dxy',\n",
       "  'Electron_dz',\n",
       "  'Electron_eta',\n",
       "  'Electron_mass',\n",
       "  'Electron_phi',\n",
       "  'Electron_pt',\n",
       "  'Flag_BadPFMuonFilter',\n",
       "  'Flag_EcalDeadCellTriggerPrimitiveFilter',\n",
       "  'Flag_HBHENoiseFilter',\n",
       "  'Flag_HBHENoiseIsoFilter',\n",
       "  'Flag_globalSuperTightHalo2016Filter',\n",
       "  'Flag_goodVertices',\n",
       "  'GenPart_eta',\n",
       "  'GenPart_genPartIdxMother',\n",
       "  'GenPart_mass',\n",
       "  'GenPart_pdgId',\n",
       "  'GenPart_phi',\n",
       "  'GenPart_pt',\n",
       "  'GenPart_status',\n",
       "  'GenPart_statusFlags',\n",
       "  'HLT_Ele27_WPTight_Gsf',\n",
       "  'HLT_IsoMu24',\n",
       "  'HLT_IsoTkMu24',\n",
       "  'Jet_btagDeepB',\n",
       "  'Jet_eta',\n",
       "  'Jet_genJetIdx',\n",
       "  'Jet_hadronFlavour',\n",
       "  'Jet_jetId',\n",
       "  'Jet_mass',\n",
       "  'Jet_phi',\n",
       "  'Jet_pt',\n",
       "  'Muon_charge',\n",
       "  'Muon_eta',\n",
       "  'Muon_isGlobal',\n",
       "  'Muon_isPFcand',\n",
       "  'Muon_isTracker',\n",
       "  'Muon_mass',\n",
       "  'Muon_pfRelIso04_all',\n",
       "  'Muon_phi',\n",
       "  'Muon_pt',\n",
       "  'Muon_tightId',\n",
       "  'Photon_cutBased',\n",
       "  'Photon_electronVeto',\n",
       "  'Photon_eta',\n",
       "  'Photon_genPartIdx',\n",
       "  'Photon_isScEtaEB',\n",
       "  'Photon_isScEtaEE',\n",
       "  'Photon_pfRelIso03_chg',\n",
       "  'Photon_phi',\n",
       "  'Photon_pixelSeed',\n",
       "  'Photon_pt',\n",
       "  'Photon_sieie',\n",
       "  'Photon_vidNestedWPBitmap',\n",
       "  'genWeight',\n",
       "  'nElectron',\n",
       "  'nGenPart',\n",
       "  'nJet',\n",
       "  'nMuon',\n",
       "  'nPhoton'},\n",
       " 'entries': value_accumulator(int, 814433),\n",
       " 'processtime': value_accumulator(float, 64.73540568351746),\n",
       " 'chunks': value_accumulator(int, 5)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('profile.html', 'w') as fout:\n",
    "    fout.write(profiler.output_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
